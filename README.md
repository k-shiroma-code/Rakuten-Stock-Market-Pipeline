# ðŸ“ˆ Stock Market Data Pipeline with Apache Airflow

A modular, containerized data pipeline that extracts, processes, and stores historical stock price data using **Apache Airflow**, **MinIO**, and **Docker**. Inspired by *Marc Lambertiâ€™s Apache Airflow: The Hands-On Guide*.

## ðŸ”§ What It Does

This project sets up an end-to-end data pipeline that:

- **Extracts** daily stock prices from the RKUNY API via custom Airflow hooks
- **Stores** raw JSON responses in a MinIO bucket (`stock-market/raw`)
- **Formats** the data into CSV using a Dockerized task
- **Uploads** the processed file to `stock-market/formatted_prices/` in MinIO

> âœ… Currently working: Full DAG run using `astro dev start`  
> âš ï¸ In progress: Robust API error handling, Slack alerts, and monitoring dashboards

---

## ðŸ—‚ DAG Structure

stock_market_dag
â”œâ”€â”€ get_stock_prices --> Calls RKUNY API and stores raw JSON
â”œâ”€â”€ store_prices --> Uploads to MinIO stock-market/raw
â”œâ”€â”€ format_prices --> DockerOperator runs CSV formatting
â””â”€â”€ get_formatted_csv --> Confirms upload to formatted_prices/


airflow dags test stock_market 2025-01-01



